{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d38e302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score on the fifth dataset: 0.6344514586880255\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "385b09a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.677733376263724"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv(\"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_AAPL_filtered.csv\")    #read file.\n",
    "\n",
    "\n",
    "#feature selection \n",
    "X=df[[\"comment_num\", \"retweet_num\", \"like_num\", \"follower_count\", \"compound_score\", \"Close_price-today\", \"Close_price-tmr\"]]#repeat for other columns\n",
    "y = df['Close_price-2days']\n",
    "X\n",
    "\n",
    "# get average of close-price-today column's value\n",
    "avg = X['Close_price-today'].mean()\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4b9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d139b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature visualization\n",
    "#histogram and cdf for today, tomorrow, 2 days with appropriate bin size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ae7b224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.78149517, 0.07543664,\n",
       "        0.08375865],\n",
       "       [0.        , 0.        , 0.00108932, ..., 0.62651212, 0.07543664,\n",
       "        0.08375865],\n",
       "       [0.        , 0.        , 0.00108932, ..., 0.49997469, 0.07543664,\n",
       "        0.08375865],\n",
       "       ...,\n",
       "       [0.00938967, 0.        , 0.00326797, ..., 0.7133168 , 0.99644311,\n",
       "        0.99794804],\n",
       "       [0.00469484, 0.        , 0.00108932, ..., 0.51303336, 0.99644311,\n",
       "        0.99794804],\n",
       "       [0.00469484, 0.        , 0.00108932, ..., 0.76656375, 0.99644311,\n",
       "        0.99794804]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "86fcb4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 3  list of results:\n",
      "[0.9966389424911594, 0.9966589119499341, 0.9965888363062463]\n",
      "For k = 3  the average result is 0.9966288969157799\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "\n",
    "#sample code\n",
    "lin_reg = LinearRegression()\n",
    "np.random.seed(40)  # to make this code example reproducible\n",
    "\n",
    "#kfold = KFold(n_splits=3, shuffle=True, random_state=42) #--->here k=3 with 3-fold cross validation.\n",
    "#random_state controls randomness of each fold.\n",
    "scores = []\n",
    "k = 3\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "for i, (train, test) in enumerate(kfold.split(X_scaled, y)):#--->splitting into train and test set.\n",
    "    lin_reg.fit(X_scaled[train], y[train])\n",
    "    #Y_pred = regression.predict(X[test])\n",
    "    temp_score = lin_reg.score(X_scaled[test], y[test])\n",
    "    scores.append(temp_score)\n",
    "print(\"For k =\", k, \" list of results:\")\n",
    "print(scores)\n",
    "print(\"For k =\", k, \" the average result is\", mean(scores))\n",
    "scores = []\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a140939a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.778864092945412"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_TSLA_filtered.csv\")    #read file.\n",
    "\n",
    "#feature selection \n",
    "X=df[[\"comment_num\", \"retweet_num\", \"like_num\", \"follower_count\", \"compound_score\", \"Close_price-today\", \"Close_price-tmr\"]]#repeat for other columns\n",
    "y = df['Close_price-2days']\n",
    "# X.head()\n",
    "# y.head()\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# pd.DataFrame(X_scaled).head()\n",
    "avg = X['Close_price-today'].mean()\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6379c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0.0\n",
      "T [     0      2      6 ... 331312 331316 331319]\n",
      "T [     1      4      9 ... 331306 331308 331317]\n",
      "T [     3      5      8 ... 331314 331315 331318]\n",
      "For k = 3  list of results:\n",
      "[0.9724340566450659, 0.9725077792376345, 0.972879916513754]\n",
      "For k = 3  the average result is 0.9726072507988182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "print(scores)\n",
    "\n",
    "print(lin_reg.score(X[:3], y[:3]))\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "#lin_reg = LinearRegression()\n",
    "for i, (train, test) in enumerate(kfold.split(X_scaled, y)):#--->splitting into train and test set.\n",
    "    #lin_reg.fit(X_scaled[train], y[train])\n",
    "    #Y_pred = regression.predict(X[test])\n",
    "    print(\"T\", test)\n",
    "    temp_score = lin_reg.score(X_scaled[test], y[test])\n",
    "    scores.append(temp_score)\n",
    "print(\"For k =\", k, \" list of results:\")\n",
    "print(scores)\n",
    "print(\"For k =\", k, \" the average result is\", mean(scores))\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19b9aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 3  list of results:\n",
      "[0.972787975683827, 0.9728574721102173, 0.9732091345886396]\n",
      "For k = 3  the average result is 0.9729515274608946\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "#bayes_reg = linear_model.BayesianRidge()\n",
    "scores=[]\n",
    "#lin_reg = LinearRegression()\n",
    "for i, (train, test) in enumerate(kfold.split(X_scaled, y)):#--->splitting into train and test set.\n",
    "    #bayes_reg.fit(X_scaled[train], y[train])\n",
    "    #Y_pred = regression.predict(X[test])\n",
    "    temp_score = lin_reg.score(X_scaled[test], y[test])\n",
    "    scores.append(temp_score)\n",
    "print(\"For k =\", k, \" list of results:\")\n",
    "print(scores)\n",
    "print(\"For k =\", k, \" the average result is\", mean(scores))\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ea519fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-64-3f49ee78246e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-3f49ee78246e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    sudo pip install keras\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sudo pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34fc5d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-59ff2cda1a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleRNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/distribute/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msidecar_evaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/distribute/sidecar_evaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Python module for evaluation loop.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# isort: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\"\"\"\n",
    "length_data = len(data)     # rows that data has\n",
    "split_ratio = 0.7           # %70 train + %30 validation\n",
    "length_train = round(length_data * split_ratio)  \n",
    "length_validation = length_data - length_train\n",
    "print(\"Data length :\", length_data)\n",
    "print(\"Train data length :\", length_train)\n",
    "print(\"Validation data lenth :\", length_validation)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#####\n",
    "\n",
    "X_train, X_test,\n",
    "y_train, y_test = train_test_split(X,y ,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.25, \n",
    "                                   shuffle=True)\n",
    "\n",
    "\n",
    "# initializing the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# adding first RNN layer and dropout regulatization\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50, \n",
    "              activation = \"tanh\", \n",
    "              return_sequences = True, \n",
    "              input_shape = (X_train.shape[1],1))\n",
    "             )\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2)\n",
    "             )\n",
    "\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50, \n",
    "              activation = \"tanh\", \n",
    "              return_sequences = True)\n",
    "             )\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2)\n",
    "             )\n",
    "\n",
    "# adding third RNN layer and dropout regulatization\n",
    "\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50, \n",
    "              activation = \"tanh\", \n",
    "              return_sequences = True)\n",
    "             )\n",
    "\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2)\n",
    "             )\n",
    "\n",
    "# adding fourth RNN layer and dropout regulatization\n",
    "\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50)\n",
    "             )\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2)\n",
    "             )\n",
    "\n",
    "# adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# compiling RNN\n",
    "regressor.compile(\n",
    "    optimizer = \"adam\", \n",
    "    loss = \"mean_squared_error\",\n",
    "    metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "# fitting the RNN\n",
    "history = regressor.fit(X_train, y_train, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c96614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

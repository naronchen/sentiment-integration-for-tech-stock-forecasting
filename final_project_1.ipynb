{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d38e302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score on the fifth dataset: 0.6344514586880255\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "filepaths = [\n",
    "    \"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_AAPL_filtered.csv\",\n",
    "    \"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_TSLA_filtered.csv\",\n",
    "    \"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_MSFT_filtered.csv\",\n",
    "    \"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_GOOG_filtered.csv\",\n",
    "    \"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_AMZN_filtered.csv\",\n",
    "]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train the model using the first four datasets\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "for filepath in filepaths[:-1]:\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    X = df[[\"comment_num\", \"retweet_num\", \"like_num\", \"follower_count\", \"compound_score\", \"Close_price-today\", \"Close_price-tmr\"]]\n",
    "    y = df['Close_price-2days']\n",
    "\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train_list.append(X_scaled)\n",
    "    y_train_list.append(y.values)\n",
    "\n",
    "X_train = np.vstack(X_train_list)\n",
    "y_train = np.concatenate(y_train_list)\n",
    "\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the fifth dataset\n",
    "df_test = pd.read_csv(filepaths[-1])\n",
    "\n",
    "X_test = df_test[[\"comment_num\", \"retweet_num\", \"like_num\", \"follower_count\", \"compound_score\", \"Close_price-today\", \"Close_price-tmr\"]]\n",
    "y_test = df_test['Close_price-2days']\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "test_score = lin_reg.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Test score on the fifth dataset:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "385b09a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Ultimate_AAPL_filtered.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s6/jdcxt52n79g1xkx16mm4x8yr0000gn/T/ipykernel_36320/1657575469.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ultimate_AAPL_filtered.csv\"\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#read file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#feature selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Ultimate_AAPL_filtered.csv'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_1=pd.read_csv(\"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_AAPL_filtered.csv\")    #read file.\n",
    "df_2=pd.read_csv(\"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_TSLA_filtered.csv\")    #read file.\n",
    "df_3=pd.read_csv(\"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_MSFT_filtered.csv\")    #read file.\n",
    "df_4=pd.read_csv(\"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_GOOG_filtered.csv\")    #read file.\n",
    "df_5=pd.read_csv(\"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_AMZN_filtered.csv\")    #read file.\n",
    "\n",
    "\n",
    "#feature selection \n",
    "X=df[[\"comment_num\", \"retweet_num\", \"like_num\", \"follower_count\", \"compound_score\", \"Close_price-today\", \"Close_price-tmr\"]]#repeat for other columns\n",
    "y = df['Close_price-2days']\n",
    "X\n",
    "\n",
    "# get average of close-price-today column's value\n",
    "avg = X['Close_price-today'].mean()\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4b9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d139b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature visualization\n",
    "#histogram and cdf for today, tomorrow, 2 days with appropriate bin size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae7b224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.78149517, 0.07543664,\n",
       "        0.08375865],\n",
       "       [0.        , 0.        , 0.00108932, ..., 0.62651212, 0.07543664,\n",
       "        0.08375865],\n",
       "       [0.        , 0.        , 0.00108932, ..., 0.49997469, 0.07543664,\n",
       "        0.08375865],\n",
       "       ...,\n",
       "       [0.00938967, 0.        , 0.00326797, ..., 0.7133168 , 0.99644311,\n",
       "        0.99794804],\n",
       "       [0.00469484, 0.        , 0.00108932, ..., 0.51303336, 0.99644311,\n",
       "        0.99794804],\n",
       "       [0.00469484, 0.        , 0.00108932, ..., 0.76656375, 0.99644311,\n",
       "        0.99794804]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86fcb4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 3  list of results:\n",
      "[0.9966389424911594, 0.9966589119499341, 0.9965888363062463]\n",
      "For k = 3  the average result is 0.9966288969157799\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "\n",
    "#sample code\n",
    "lin_reg = LinearRegression()\n",
    "np.random.seed(40)  # to make this code example reproducible\n",
    "\n",
    "#kfold = KFold(n_splits=3, shuffle=True, random_state=42) #--->here k=3 with 3-fold cross validation.\n",
    "#random_state controls randomness of each fold.\n",
    "scores = []\n",
    "k = 3\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "for i, (train, test) in enumerate(kfold.split(X_scaled, y)):#--->splitting into train and test set.\n",
    "    lin_reg.fit(X_scaled[train], y[train])\n",
    "    #Y_pred = regression.predict(X[test])\n",
    "    temp_score = lin_reg.score(X_scaled[test], y[test])\n",
    "    scores.append(temp_score)\n",
    "print(\"For k =\", k, \" list of results:\")\n",
    "print(scores)\n",
    "print(\"For k =\", k, \" the average result is\", mean(scores))\n",
    "scores = []\n",
    "print(\" \")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a140939a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.778864092945412"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"./dev/sentiment-integration-for-tech-stock-forecasting/Ultimate_TSLA_filtered.csv\")    #read file.\n",
    "\n",
    "#feature selection \n",
    "X=df[[\"comment_num\", \"retweet_num\", \"like_num\", \"follower_count\", \"compound_score\", \"Close_price-today\", \"Close_price-tmr\"]]#repeat for other columns\n",
    "y = df['Close_price-2days']\n",
    "# X.head()\n",
    "# y.head()\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# pd.DataFrame(X_scaled).head()\n",
    "avg = X['Close_price-today'].mean()\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6379c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0.0\n",
      "T [     0      2      6 ... 331312 331316 331319]\n",
      "T [     1      4      9 ... 331306 331308 331317]\n",
      "T [     3      5      8 ... 331314 331315 331318]\n",
      "For k = 3  list of results:\n",
      "[-68.94237018966699, -68.47954728701083, -68.47092123726388]\n",
      "For k = 3  the average result is -68.63094623798057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "print(scores)\n",
    "\n",
    "print(lin_reg.score(X[:3], y[:3]))\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "#lin_reg = LinearRegression()\n",
    "for i, (train, test) in enumerate(kfold.split(X_scaled, y)):#--->splitting into train and test set.\n",
    "    #lin_reg.fit(X_scaled[train], y[train])\n",
    "    #Y_pred = regression.predict(X[test])\n",
    "    print(\"T\", test)\n",
    "    temp_score = lin_reg.score(X_scaled[test], y[test])\n",
    "    scores.append(temp_score)\n",
    "print(\"For k =\", k, \" list of results:\")\n",
    "print(scores)\n",
    "print(\"For k =\", k, \" the average result is\", mean(scores))\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19b9aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 3  list of results:\n",
      "[0.9966391627098399, 0.9966589938285656, 0.9965888363062463]\n",
      "For k = 3  the average result is 0.9966289976148839\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "#bayes_reg = linear_model.BayesianRidge()\n",
    "scores=[]\n",
    "#lin_reg = LinearRegression()\n",
    "for i, (train, test) in enumerate(kfold.split(X_scaled, y)):#--->splitting into train and test set.\n",
    "    #bayes_reg.fit(X_scaled[train], y[train])\n",
    "    #Y_pred = regression.predict(X[test])\n",
    "    temp_score = lin_reg.score(X_scaled[test], y[test])\n",
    "    scores.append(temp_score)\n",
    "print(\"For k =\", k, \" list of results:\")\n",
    "print(scores)\n",
    "print(\"For k =\", k, \" the average result is\", mean(scores))\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ea519fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-64-3f49ee78246e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-3f49ee78246e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    sudo pip install keras\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sudo pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34fc5d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-59ff2cda1a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleRNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/distribute/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msidecar_evaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/distribute/sidecar_evaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Python module for evaluation loop.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# isort: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\"\"\"\n",
    "length_data = len(data)     # rows that data has\n",
    "split_ratio = 0.7           # %70 train + %30 validation\n",
    "length_train = round(length_data * split_ratio)  \n",
    "length_validation = length_data - length_train\n",
    "print(\"Data length :\", length_data)\n",
    "print(\"Train data length :\", length_train)\n",
    "print(\"Validation data lenth :\", length_validation)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#####\n",
    "\n",
    "X_train, X_test,\n",
    "y_train, y_test = train_test_split(X,y ,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.25, \n",
    "                                   shuffle=True)\n",
    "\n",
    "\n",
    "# initializing the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# adding first RNN layer and dropout regulatization\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50, \n",
    "              activation = \"tanh\", \n",
    "              return_sequences = True, \n",
    "              input_shape = (X_train.shape[1],1))\n",
    "             )\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2)\n",
    "             )\n",
    "\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50, \n",
    "              activation = \"tanh\", \n",
    "              return_sequences = True)\n",
    "             )\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2)\n",
    "             )\n",
    "\n",
    "# adding third RNN layer and dropout regulatization\n",
    "\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50, \n",
    "              activation = \"tanh\", \n",
    "              return_sequences = True)\n",
    "             )\n",
    "\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2)\n",
    "             )\n",
    "\n",
    "# adding fourth RNN layer and dropout regulatization\n",
    "\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50)\n",
    "             )\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2)\n",
    "             )\n",
    "\n",
    "# adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# compiling RNN\n",
    "regressor.compile(\n",
    "    optimizer = \"adam\", \n",
    "    loss = \"mean_squared_error\",\n",
    "    metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "# fitting the RNN\n",
    "history = regressor.fit(X_train, y_train, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c96614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
